"""
üìò AI & RAG Project Glossary
Simple explanations of key terms used in the RAG AI PDF Agent.
"""

# ==============================
# üß† CORE CONCEPTS
# ==============================

# 1Ô∏è‚É£ RAG (Retrieval-Augmented Generation)
# Combines search + AI generation. The system first retrieves relevant text from a database
# (like Qdrant), then sends that context to an LLM (like Gemini) to generate an answer.
# Example: You upload a PDF, ask a question ‚Äî RAG retrieves the relevant page
# and Gemini answers based on that page.

# 2Ô∏è‚É£ Embedding
# A numerical representation (vector) of text, created by a model like SentenceTransformer.
# Words/sentences with similar meaning have vectors close to each other.
# Example: "dog" and "puppy" ‚Üí similar embeddings.

# 3Ô∏è‚É£ Vector
# A list of numbers that represents data (like a text chunk) in high-dimensional space.
# Example: [0.12, -0.45, 0.88, ...] ‚Äî 384 numbers for "all-MiniLM-L6-v2".

# 4Ô∏è‚É£ Vector Database (Qdrant)
# A special database that stores embeddings (vectors) and allows similarity searches.
# Instead of matching text exactly, it finds the most *semantically similar* data.
# Example: Searching "weather forecast" might also match "climate prediction".

# 5Ô∏è‚É£ Chunking
# Breaking long text into smaller, overlapping pieces for better search and embedding.
# Example: Splitting a 10-page PDF into 200-word chunks.

# 6Ô∏è‚É£ Overlap
# Repeating a small part of the previous chunk in the next one to keep context connected.
# Example: Last 2 sentences of chunk A appear again at start of chunk B.

# 7Ô∏è‚É£ Similarity Search
# Finds vectors (text chunks) most similar to a given query vector.
# Example: "What is AI?" ‚Üí finds chunks talking about artificial intelligence.

# ==============================
# ‚öôÔ∏è TOOLS & FRAMEWORKS
# ==============================

# 8Ô∏è‚É£ FastAPI
# A Python web framework for building APIs quickly.
# Example: You define endpoints like /ingest or /query to trigger backend functions.

# 9Ô∏è‚É£ Inngest
# Event-driven workflow engine that automates steps (like load ‚Üí embed ‚Üí upsert).
# Example: When a PDF upload event happens, Inngest automatically runs the RAG ingestion pipeline.

# üîü Qdrant
# Open-source vector database used for semantic search.
# Stores (id, vector, payload) triples.
# Example: Stores chunks of PDF text + their embeddings.

# 11Ô∏è‚É£ SentenceTransformer
# Model that converts text into embeddings.
# Example: model.encode(["Hello world"]) ‚Üí vector of 384 numbers.

# 12Ô∏è‚É£ Payload
# Extra info stored with a vector (metadata like source, text, or ID).
# Example: payload = {"source": "file1.pdf", "text": "AI is intelligence in machines."}

# 13Ô∏è‚É£ UUID
# Unique identifier for each chunk, often generated from source name and index.
# Example: "c839c9b6-efaa-4f8e-bec9-9326bb7c25d3"

# 14Ô∏è‚É£ Environment Variables (.env)
# Secure way to store API keys or configuration values.
# Example: GEMINI_API_KEY="abcdef123"

# 15Ô∏è‚É£ Gemini (via OpenAI API)
# Google‚Äôs AI model, used for generating answers using the context retrieved from Qdrant.
# Example: Model reads relevant chunks and answers your question.

# 16Ô∏è‚É£ COSINE Distance
# Measures similarity between two vectors ‚Äî smaller angle = more similar meaning.
# Example: cosine(‚Äúdog‚Äù, ‚Äúpuppy‚Äù) ‚âà high similarity.

# 17Ô∏è‚É£ Context
# The retrieved text given to the LLM so it can generate an accurate answer.
# Example: ‚ÄúAccording to page 4, AI was first coined in 1956...‚Äù

# ==============================
# üíª PIPELINE OVERVIEW
# ==============================

# Step 1: Upload PDF
# Step 2: Split into chunks (chunking)
# Step 3: Create embeddings (SentenceTransformer)
# Step 4: Store vectors in Qdrant
# Step 5: Ask a question ‚Üí embed query ‚Üí search similar chunks
# Step 6: Send found chunks + question ‚Üí Gemini ‚Üí get answer
