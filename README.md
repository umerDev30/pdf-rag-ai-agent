ğŸ§  RAG AI Agent

A Retrieval-Augmented Generation (RAG) system that lets you upload and query PDFs â€” combining semantic search with generative AI answers.
This project uses SentenceTransformer for embeddings, Qdrant (via Docker) as a vector database, and Gemini API (through OpenAI-compatible endpoints) for answer generation.
All dependencies are managed using UV, the next-generation Python package manager.

ğŸš€ Features

ğŸ“„ PDF Ingestion â€” Chunk and embed document content using SentenceTransformers

ğŸ” Semantic Search â€” Store and retrieve document vectors from Qdrant

ğŸ¤– AI-Powered Answers â€” Use Gemini (via OpenAI endpoints) to generate contextual answers

âš™ï¸ Event-Driven Workflow â€” Powered by Inngest for scalable function execution

ğŸŒ FastAPI Backend and optional Streamlit Frontend for interactive querying

ğŸ§© Containerized Vector DB â€” Qdrant runs fully in Docker

ğŸ§° UV-Based Project â€” Modern, reproducible dependency management

ğŸ—ï¸ Tech Stack
Component	Tool / Library
Language	Python 3.12+
Package Manager	UV
Web Framework	FastAPI
Vector Database	Qdrant (Docker)
Embeddings	SentenceTransformers
LLM	Google Gemini API (via OpenAI-compatible endpoints)
Event Handling	Inngest
Frontend	Streamlit
ğŸ§© Project Structure
rag-ai-agent/
â”‚
â”œâ”€â”€ __pycache__/            # Python cache files
â”œâ”€â”€ .venv/                  # Virtual environment created by UV
â”‚
â”œâ”€â”€ qdrant_storage/         # Local folder mounted to Docker for persistent Qdrant data
â”œâ”€â”€ uploads/                # Folder for uploaded PDFs
â”‚
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ .python-version         # Python version specification (for UV/pyenv)
â”‚
â”œâ”€â”€ custom_types.py         # Pydantic models for data schemas
â”œâ”€â”€ data_loader.py          # Loads and chunks PDF content
â”œâ”€â”€ glossary.py             # Contains simplified definitions for technical terms
â”œâ”€â”€ main.py                 # FastAPI app entrypoint
â”œâ”€â”€ reset_qdrant.py         # Script to reset or clear Qdrant collections
â”œâ”€â”€ streamlit_app.py        # Streamlit frontend interface
â”œâ”€â”€ vector_db.py            # Handles Qdrant vector operations
â”‚
â”œâ”€â”€ pyproject.toml          # Project dependencies (UV)
â”œâ”€â”€ requirements.txt        # Optional standard dependency list
â”œâ”€â”€ uv.lock                 # Dependency lockfile for reproducibility
â””â”€â”€ README.md               # Project documentation


ğŸ—‚ï¸ Note:

qdrant_storage/ â€” created by Docker for persistent Qdrant data.

uploads/ â€” stores uploaded PDFs for processing.

reset_qdrant.py â€” helper to clear or reset your Qdrant database.

âš™ï¸ Setup & Run Commands (Sequential)
1. Clone the Repository
git clone https://github.com/umerDev30/rag-ai-agent.git
cd rag-ai-agent

2. Start Qdrant via Docker
docker run -d --name qdrantRagDb \
  -p 6333:6333 \
  -v "${PWD}/qdrant_storage:/qdrant/storage" \
  qdrant/qdrant


The qdrant_storage folder is automatically created for persistent Qdrant data.

3. Create the .env File
GEMINI_API_KEY=your_gemini_key
QDRANT_URL=http://localhost:6333

4. Initialize the Project
uv init

5. Install Dependencies
uv sync

6. Run the FastAPI Server
uv run uvicorn main:app


Server will start at: http://127.0.0.1:8000

7. Start the Inngest Dev Server (for ingestion events)
inngest dev -u http://127.0.0.1:8000/api/inngest --no-discovery

8. (Optional) Launch Streamlit Frontend
uv run streamlit run .\streamlit_app.py


Streamlit will open at: http://localhost:8501

ğŸ§  How It Works

PDF Upload â†’ Chunking â€” data_loader.py splits documents into overlapping text chunks.

Embedding â†’ Storage â€” Chunks are embedded via SentenceTransformer and stored in Qdrant.

User Query â†’ Retrieval â€” The query is embedded and matched against stored vectors.

Context â†’ Generation â€” Retrieved text is passed to Gemini for generating answers.

Response â†’ User â€” Returns a concise, context-aware answer.

ğŸ§© Example Usage

Query Example:

â€œWhat does the document say about revenue growth?â€

Response:

â€œThe report indicates that revenue grew by 15% year-over-year due to strong Q2 performance.â€

ğŸ§± Future Enhancements

ğŸ§¬ Support for multiple document formats (DOCX, TXT)

ğŸ•¸ï¸ Multi-source retrieval (web + PDFs)

â˜ï¸ Cloud deployment (AWS / GCP)

ğŸ§­ Improved ranking using cross-encoders
